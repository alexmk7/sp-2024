{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основные понятия\n",
    "\n",
    "**Topic** - все сообщения в Kafka приходят в определенный топик, по сути это простой способ организовать и сгруппировать поток сообытий. Каждый топик имеет уникальное имя. \n",
    "\n",
    "**Producers (производитель)**  - компонент системы, клиентское приложение, которое генерирует сообщения и посылает их в определенный топик. \n",
    "\n",
    "**Consumers (потребитель)** - компонент системы, клиентское приложение, которое получает новые сообщения из определенного топика или набора топиков. \n",
    "\n",
    "**Partition** - топик, как логическое понятие, неразделим. Но физически он может состоять из нескольких партиций, которые физически хранятся на нескольких узлах кластера. Когда сообщение приходит в топик, оно физически записывается в только одну партицию.  \n",
    "<img src=\"https://kafka.apache.org/images/streams-and-tables-p1_p4.png\" alt=\"kafka\" style=\"width:500px;\"/>\n",
    "\n",
    "**Consumer group** - это набор потребителей, которые кооперируются для получения данных из определенного топика. Все партиции топика разделяются между членами группы. По мере входа новых членов группы и ухода старых, партиции перераспределяются так, чтобы каждый член получал пропорциональную долю партиций для чтения. Этот процесс называется ребалансировкой группы.\n",
    "\n",
    "**At-least-once** - гарантируется, что сообщения никогда не теряются, но могут быть доставлены повторно. Если  приложение потоковой обработки падает, то некоторые сообщения могут быть посланы повторно и, следовательно, повторно обработаны. Семантика «хотя бы один раз» включена по умолчанию.\n",
    "\n",
    "**Exactly-once** - сообщения обрабатываются строго один раз. Подобная семантика включается опционально. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск в `Docker`:\n",
    "\n",
    "```bash\n",
    "docker compose -f docker/docker-compose-kafka.yml up\n",
    "```       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer, Consumer, TopicPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPIC_NAME = \"some_topic\"\n",
    "\n",
    "producer = Producer({\n",
    "        \"bootstrap.servers\": \"localhost:9092\"\n",
    "    })\n",
    "\n",
    "for idx in range(0, 25):\n",
    "    producer.produce(TOPIC_NAME, key=bytes(idx), value=b\"Msg %d\" % idx)\n",
    "    producer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Msg 0'\n",
      "b'Msg 1'\n",
      "b'Msg 2'\n",
      "b'Msg 3'\n",
      "b'Msg 4'\n",
      "b'Msg 5'\n",
      "b'Msg 6'\n",
      "b'Msg 7'\n",
      "b'Msg 8'\n",
      "b'Msg 9'\n",
      "b'Msg 10'\n",
      "b'Msg 11'\n",
      "b'Msg 12'\n",
      "b'Msg 13'\n",
      "b'Msg 14'\n",
      "b'Msg 15'\n",
      "b'Msg 16'\n",
      "b'Msg 17'\n",
      "b'Msg 18'\n",
      "b'Msg 19'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "%3|1726086499.511|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT)\n",
      "%3|1726086500.515|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 1 identical error(s) suppressed)\n",
      "%3|1726086530.698|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086560.754|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086590.793|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086620.853|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086650.890|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086680.931|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086710.963|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 31 identical error(s) suppressed)\n",
      "%3|1726086741.007|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n",
      "%3|1726086771.050|FAIL|rdkafka#producer-1| [thrd:localhost:9092/bootstrap]: localhost:9092/1: Connect to ipv4#127.0.0.1:9092 failed: Connection refused (after 0ms in state CONNECT, 30 identical error(s) suppressed)\n"
     ]
    }
   ],
   "source": [
    "consumer = Consumer({\n",
    "    \"bootstrap.servers\": \"localhost:9092\",\n",
    "    \"group.id\": \"group1\",\n",
    "    \"auto.offset.reset\": \"earliest\"\n",
    "})\n",
    "\n",
    "consumer.subscribe([TOPIC_NAME])\n",
    "\n",
    "# tp = TopicPartition(topic=TOPIC_NAME, partition=0, offset=0)\n",
    "# consumer.assign([tp])\n",
    "# consumer.seek(tp)\n",
    "\n",
    "for _ in range(25):\n",
    "    msg = consumer.consume(num_messages=1, timeout=1.0)\n",
    "    if len(msg) > 0:\n",
    "        print(msg[0].value()) \n",
    "\n",
    "consumer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kafka Streams\n",
    "\n",
    "Надстройка (клиент), который позволяет разрабатывать приложения, которые удобно манипулируют данными в топиках `Kafka`. Есть `JVM API`  и специальный `SQL`-подобный язык, который работает с сервером `ksqlDB`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся `ksqlDB` клиентом для `Python`. Он плохо поддерживается, поэтому несовместим без определенных изменений с последними версиями `CPython`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Необходимые патчи, чтобы вернуть работоспособность библиотеке \n",
    "import sys\n",
    "import json\n",
    "\n",
    "if sys.version_info.minor > 9:\n",
    "    import collections\n",
    "    collections.Iterable = collections.abc.Iterable\n",
    "    collections.Mapping = collections.abc.Mapping\n",
    "    collections.MutableSet = collections.abc.MutableSet\n",
    "    collections.MutableMapping = collections.abc.MutableMapping\n",
    "\n",
    "from ksql import KSQLAPI\n",
    "\n",
    "# https://github.com/bryanyang0528/ksql-python/issues/80\n",
    "class KsqlApiCustom(KSQLAPI):\n",
    "    def __init__(self, url, max_retries=3, check_version=True, **kwargs):\n",
    "        super().__init__(url, max_retries=max_retries,\n",
    "                         check_version=check_version, **kwargs)\n",
    "        self.sa._raise_for_status = self._raise_for_status\n",
    "\n",
    "    @staticmethod\n",
    "    def _raise_for_status(r, response):\n",
    "        r_json = json.loads(response)\n",
    "        if r.getcode() != 200:\n",
    "            if r_json.get(\"@type\") == \"statement_error\" or r_json.get(\"@type\") == \"generic_error\":\n",
    "                error_message = r_json[\"message\"]\n",
    "                error_code = r_json[\"error_code\"]\n",
    "                stackTrace = r_json[\"stack_trace\"]\n",
    "                raise KSQLError(error_message, error_code, stackTrace)\n",
    "            else:\n",
    "                raise KSQLError(\"Unknown Error: {}\".format(r.content))\n",
    "        else:\n",
    "            # seems to be the old API behavior, so some errors have status 200, bug??\n",
    "            if r_json and r_json[0][\"@type\"] == \"currentStatus\" and r_json[0][\"commandStatus\"][\"status\"] == \"ERROR\":\n",
    "                error_message = r_json[0][\"commandStatus\"][\"message\"]\n",
    "                error_code = None\n",
    "                stackTrace = None\n",
    "                raise KSQLError(error_message, error_code, stackTrace)\n",
    "            return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем клиента и соединяемся с сервером `ksqlDB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = KsqlApiCustom('http://127.0.0.1:8788')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим `Stream` - непрерывный, неограниченный поток данных. Каждый элемент потока - пара ключ/значение. Представляет собой обертку над топиками kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@type': 'currentStatus',\n",
       "  'statementText': \"CREATE STREAM RIDER_LOCATIONS (PROFILEID STRING, LATITUDE DOUBLE, LONGITUDE DOUBLE) WITH (KAFKA_TOPIC='locations', KEY_FORMAT='KAFKA', PARTITIONS=1, VALUE_FORMAT='JSON');\",\n",
       "  'commandId': 'stream/`RIDER_LOCATIONS`/create',\n",
       "  'commandStatus': {'status': 'SUCCESS',\n",
       "   'message': 'Stream created',\n",
       "   'queryId': None},\n",
       "  'commandSequenceNumber': 0,\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql(\n",
    "    \"\"\"\n",
    "    CREATE STREAM rider_locations (profileId VARCHAR, latitude DOUBLE, longitude DOUBLE)\n",
    "    WITH (kafka_topic='locations', value_format='json', partitions=1)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим две \"таблицы\", которые представляет из себя слепок состояния `Stream`'а, определяемым по некоторым правилам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@type': 'currentStatus',\n",
       "  'statementText': \"CREATE TABLE RIDERS_NEAR_MOUNTAIN_VIEW WITH (KAFKA_TOPIC='RIDERS_NEAR_MOUNTAIN_VIEW', PARTITIONS=1, REPLICAS=1) AS SELECT\\n  ROUND(GEO_DISTANCE(CURRENT_LOCATION.LA, CURRENT_LOCATION.LO, 37.4133, -122.1162), -1) DISTANCEINMILES,\\n  COLLECT_LIST(CURRENT_LOCATION.PROFILEID) RIDERS,\\n  COUNT(*) COUNT\\nFROM CURRENT_LOCATION CURRENT_LOCATION\\nGROUP BY ROUND(GEO_DISTANCE(CURRENT_LOCATION.LA, CURRENT_LOCATION.LO, 37.4133, -122.1162), -1)\\nEMIT CHANGES;\",\n",
       "  'commandId': 'table/`RIDERS_NEAR_MOUNTAIN_VIEW`/create',\n",
       "  'commandStatus': {'status': 'SUCCESS',\n",
       "   'message': 'Created query with ID CTAS_RIDERS_NEAR_MOUNTAIN_VIEW_3',\n",
       "   'queryId': 'CTAS_RIDERS_NEAR_MOUNTAIN_VIEW_3'},\n",
       "  'commandSequenceNumber': 4,\n",
       "  'warnings': []}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.ksql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE current_location AS\n",
    "        SELECT profileId,\n",
    "                LATEST_BY_OFFSET(latitude) AS la,\n",
    "                LATEST_BY_OFFSET(longitude) AS lo\n",
    "        FROM rider_locations\n",
    "        GROUP BY profileId\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "client.ksql(\n",
    "    \"\"\"\n",
    "    CREATE TABLE riders_near_mountain_view AS\n",
    "        SELECT ROUND(GEO_DISTANCE(la, lo, 37.4133, -122.1162), -1) AS distanceInMiles,\n",
    "                COLLECT_LIST(profileId) AS riders,\n",
    "                COUNT(*) AS count\n",
    "        FROM current_location\n",
    "        GROUP BY ROUND(GEO_DISTANCE(la, lo, 37.4133, -122.1162), -1)\n",
    "    \"\"\"\n",
    ")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем в `Stream` данные с помощью функции `INSERT` (физически данные добавятся в топик `Kafka`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "    \n",
    "\n",
    "def insert_in_thread():\n",
    "    time.sleep(10)\n",
    "    client.ksql(\n",
    "        \"\"\"\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('c2309eec', 37.7877, -122.4205);\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('18f4ea86', 37.3903, -122.0643);\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('4ab5cbad', 37.3952, -122.0813);\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('8b6eae59', 37.3944, -122.0813);\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('4a7c7b41', 37.4049, -122.0822);\n",
    "        INSERT INTO rider_locations (profileId, latitude, longitude) VALUES ('4ddad000', 37.7857, -122.4011)\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "thread = threading.Thread(target=insert_in_thread)    \n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрос типа `PUSH` (c `EMIT CHANGES`) работает бесконечно, генерируя обновления таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PROFILEID': '4ab5cbad', 'LATITUDE': 37.3952, 'LONGITUDE': -122.0813}\n",
      "{'PROFILEID': '8b6eae59', 'LATITUDE': 37.3944, 'LONGITUDE': -122.0813}\n",
      "{'PROFILEID': '4a7c7b41', 'LATITUDE': 37.4049, 'LONGITUDE': -122.0822}\n"
     ]
    }
   ],
   "source": [
    "res = client.query(\n",
    "    \"\"\"\n",
    "    SELECT * FROM rider_locations\n",
    "        WHERE GEO_DISTANCE(latitude, longitude, 37.4133, -122.1162) <= 5 \n",
    "        EMIT CHANGES\n",
    "    \"\"\", return_objects=True\n",
    ")\n",
    "\n",
    "print(next(res))\n",
    "print(next(res))\n",
    "print(next(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запрос вида `PULL` возвращает текущее состояние таблицы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0,[\"4ab5cbad\",\"8b6eae59\",\"4a7c7b41\"],3]\n",
      "\n",
      "[10.0,[\"18f4ea86\"],1]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = client.query(\n",
    "    \"\"\"\n",
    "    SELECT * from riders_near_mountain_view WHERE distanceInMiles <= 10\n",
    "    \"\"\", return_objects=True, use_http2=True\n",
    ")\n",
    "\n",
    "next(res)\n",
    "for x in res:\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
